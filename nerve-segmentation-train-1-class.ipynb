{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ultrasound Nerve Segmentation\n",
    "[Kaggle Competition Link](https://www.kaggle.com/c/ultrasound-nerve-segmentation)\n",
    "\n",
    "Semantic segmentation of ultrasound images to identify nerve structures to improve catheter placement and contribute to a more pain free future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import re\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anand/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/anand/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.models import model_from_yaml\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import keras.applications.vgg16\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dropout, Add, Flatten, Dense, Reshape, Conv2D, Conv2DTranspose, GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras import losses\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.initializers import TruncatedNormal\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10957666315721455404\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7610128794\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 3711325892279228394\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# To ensure GPU is being used\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_HT = 416\n",
    "IMAGE_WD = 576\n",
    "data_dir = './data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning\n",
    "Load pre-trained VGG16 model that is trained on ImageNet data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 416, 576, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 416, 576, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 416, 576, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 208, 288, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 208, 288, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 208, 288, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 104, 144, 128)     0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 104, 144, 256)     295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 104, 144, 256)     590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 104, 144, 256)     590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 52, 72, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 52, 72, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 52, 72, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 52, 72, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 26, 36, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 26, 36, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 26, 36, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 26, 36, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 13, 18, 512)       0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG16(include_top=False, weights='imagenet', input_shape=(IMAGE_HT, IMAGE_WD, 3))\n",
    "FROZEN_LAYERS = 0\n",
    "# Freeze layers\n",
    "for idx,layer in enumerate(base_model.layers):\n",
    "  layer.trainable = idx >= FROZEN_LAYERS\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCN\n",
    "- Add deconvolutions\n",
    "- Add skip-connections\n",
    "- Do softmax to convert logits to prob. distribution\n",
    "- Reshape to [batch_size, image_width * image_height, num_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = 1\n",
    "\n",
    "regularizer = regularizers.l2(0.01)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "#x = GlobalAveragePooling2D()(x)\n",
    "#x = Dropout(0.4)(x)\n",
    "x = Conv2D(filters=num_classes, kernel_size=1, strides=1, padding='SAME', activation=None, kernel_regularizer=regularizer)(x)\n",
    "\n",
    "x = Conv2DTranspose(filters=512, kernel_size=4, strides=2, padding='SAME', activation=None, kernel_regularizer=regularizer)(x)\n",
    "\n",
    "x = Add()([x, base_model.get_layer('block4_pool').output])\n",
    "\n",
    "x = Conv2DTranspose(filters=256, kernel_size=4, strides=4, padding='SAME', activation=None, kernel_regularizer=regularizer)(x)\n",
    "\n",
    "x = Add()([x, base_model.get_layer('block3_conv3').output])\n",
    "\n",
    "x = Conv2DTranspose(filters=num_classes, kernel_size=5, strides=4, padding='SAME', activation='sigmoid', kernel_regularizer=regularizer)(x)\n",
    "\n",
    "probs = Reshape((-1, num_classes))(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "- Define custom loss function to do calculate cross-entropy\n",
    "- Dice coefficient loss used to train model - is a similarity index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smooth = 1.\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    return K.mean(K.categorical_crossentropy(y_true, y_pred, from_logits=False), axis=1)\n",
    "\n",
    "    #     y1 = y_true[:,:,0]\n",
    "    #     t1s = K.print_tensor(y1 >= 1., 'truth')\n",
    "    #     y2 = y_pred[:,:,0]\n",
    "    #     p0s = K.print_tensor(y2 > 0.5, 'pred')\n",
    "    #     stk = K.stack([t1s, p0s])\n",
    "    #     intersect = K.all(stk, axis=0)\n",
    "    #     result = K.sum(K.cast(intersect,'float32'), axis=1)\n",
    "    #     return K.print_tensor(result)\n",
    "\n",
    "    #return K.stack( (K.sum(K.all((t1s,p0s), axis=0), axis=1), K.sum(K.all((t1s,p0s), axis=0), axis=1)) )\n",
    "\n",
    "    #return K.sum(K.square(y_true[:,0:239616] * (1. - y_pred[:,0:239616])), axis=1) \n",
    "    #return K.sum(K.square(y_pred[:,0:239616] - y_true[:,0:239616]) + K.square(y_true[:,0:239616] * (1. - y_pred[:,0:239616])) * 100), axis=1)\n",
    "    #return K.sum(K.square(y_pred - y_true), axis=1)\n",
    "    #return K.mean(K.categorical_crossentropy(y_true, y_pred, from_logits=False), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model compilation\n",
    "- Select Adam optimizer\n",
    "- Select custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 416, 576, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 416, 576, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 416, 576, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 208, 288, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 208, 288, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 208, 288, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 104, 144, 128 0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 104, 144, 256 295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 104, 144, 256 590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 104, 144, 256 590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 52, 72, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 52, 72, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 52, 72, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 52, 72, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 26, 36, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 26, 36, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 26, 36, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 26, 36, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 13, 18, 512)  0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 13, 18, 1)    513         block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 26, 36, 512)  8704        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 26, 36, 512)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 104, 144, 256 2097408     add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 104, 144, 256 0           conv2d_transpose_2[0][0]         \n",
      "                                                                 block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 416, 576, 1)  6401        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 239616, 1)    0           conv2d_transpose_3[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 16,827,714\n",
      "Trainable params: 16,827,714\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-5\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer=Adam(lr=learning_rate), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data generators\n",
    "- Load images\n",
    "- Split into training and validation sets (80/20 split)\n",
    "- Select images with nerve-structures in them, skip blank images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filelist = glob.glob('./data/train_orig/*_mask.tif')\n",
    "\n",
    "val_percent = 20\n",
    "val_items = 20*len(filelist)//100\n",
    "\n",
    "random.shuffle(filelist)\n",
    "\n",
    "validation_list = filelist[0: val_items]\n",
    "train_list = filelist[val_items:]\n",
    "background_color = np.array([255, 255, 255])\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    \n",
    "    def isAllBlack(self, x):\n",
    "        return np.all(self.imread(x)[:,:] == [0,0,0])\n",
    "    \n",
    "    def __init__(self, mask_list, batch_size, input_preprocessor):\n",
    "        mask_notall_black = [x for x in mask_list if not self.isAllBlack(x)]\n",
    "        self.y = mask_notall_black\n",
    "        self.x = [grp.group(1)+grp.group(2) for grp in [re.match(r'(.*)_mask(\\.tif)', x) for x in mask_notall_black]]\n",
    "        self.batch_size = batch_size\n",
    "        self.input_preprocessor = input_preprocessor\n",
    "        \n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.x) / float(self.batch_size))\n",
    "    \n",
    "    def imread(self, file_name):\n",
    "        return cv2.imread(file_name)[2: 418, 2:578]\n",
    "    \n",
    "    def inputimage(self, file_name):\n",
    "        return self.input_preprocessor(self.imread(file_name).astype(np.float32))\n",
    "    \n",
    "    def labelread(self, file_name):\n",
    "        img = self.imread(file_name)\n",
    "        \n",
    "        gt_bg = np.all(img == background_color, axis=2)\n",
    "        gt_bg = gt_bg.reshape(*gt_bg.shape, 1)\n",
    "        \n",
    "        class1 = np.zeros(gt_bg.shape)\n",
    "        class1[gt_bg] = 1.\n",
    "        return class1.reshape(-1, num_classes)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
    "       \n",
    "        return np.array([self.inputimage(file_name) for file_name in batch_x]), np.array([self.labelread(file_name) for file_name in batch_y])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and validation data\n",
    "Create data generators for training and validation for specific batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "train_gen = DataGenerator(train_list, batch_size, input_preprocessor = keras.applications.vgg16.preprocess_input)\n",
    "val_gen = DataGenerator(validation_list, batch_size, input_preprocessor = keras.applications.vgg16.preprocess_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "188/188 [==============================] - 155s 823ms/step - loss: 2.9429 - dice_coef: 0.1295 - val_loss: 2.4457 - val_dice_coef: 0.2625\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 150s 798ms/step - loss: 2.0285 - dice_coef: 0.4366 - val_loss: 1.7368 - val_dice_coef: 0.5191\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 150s 796ms/step - loss: 1.5209 - dice_coef: 0.5615 - val_loss: 1.3199 - val_dice_coef: 0.5979\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 150s 796ms/step - loss: 1.1413 - dice_coef: 0.6309 - val_loss: 0.9790 - val_dice_coef: 0.6539\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 150s 796ms/step - loss: 0.8479 - dice_coef: 0.6612 - val_loss: 0.7207 - val_dice_coef: 0.6695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc01c707c50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 5\n",
    "saveWeights = ModelCheckpoint(filepath='./data/weights.hdf5', verbose=1, save_best_only=True)\n",
    "model.fit_generator(train_gen, validation_data = val_gen, epochs=epochs, checkpoints=[saveWeights])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "dg = DataGenerator([],1, keras.applications.vgg16.preprocess_input)\n",
    "img = dg.inputimage('./data/train_orig/1_8.tif')\n",
    "X = img.reshape((1,*img.shape))\n",
    "Y = model.predict(X)\n",
    "y = Y.reshape(416, 576)\n",
    "a=np.zeros(y.shape)\n",
    "a[y > 0.5] = 255\n",
    "cv2.imwrite('./output.pbm', a)\n",
    "print(np.min(Y), np.max(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('./data/model-2018-02-03.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
