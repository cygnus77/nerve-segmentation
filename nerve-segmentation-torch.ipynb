{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Net\n",
    "\n",
    "net = Net()\n",
    "net.cuda()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset\n",
    "\n",
    "train_loader, val_loader = dataset.create_loaders(val_percent = 20, batch_size = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images[0:4], nrow=4,padding=20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    intersection = torch.sum(y_true * y_pred)\n",
    "    return (2. * intersection + 1.) / (torch.sum(y_true) + torch.sum(y_pred) + 1.)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "def iou(y_true, y_pred):\n",
    "    intersection = torch.sum(y_true * y_pred)\n",
    "    return (intersection + 1.) / (torch.sum(y_true) + torch.sum(y_pred) - intersection + 1.)\n",
    "\n",
    "def falsepos(y_true, y_pred):\n",
    "    intersection = torch.sum(y_true * y_pred)\n",
    "    return torch.sum(y_pred) - intersection\n",
    "\n",
    "def falseneg(y_true, y_pred):\n",
    "    intersection = torch.sum(y_true * y_pred)\n",
    "    return torch.sum(y_true) - intersection\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    intersection = torch.sum(y_true * y_pred)\n",
    "    return intersection / (torch.sum(y_pred) + 1.)\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    intersection = torch.sum(y_true * y_pred)\n",
    "    return intersection / (torch.sum(y_true) + 1.)\n",
    "\n",
    "def fscore(y_true, y_pred):\n",
    "    presci = precision(y_true, y_pred)\n",
    "    rec = recall(y_true, y_pred)\n",
    "    return 2*(presci * rec)/(presci + rec)\n",
    "\n",
    "def weighted_fscore_loss(preci_weight, recall_weight):\n",
    "    def fscore_loss(y_true, y_pred):\n",
    "        presci = precision(y_true, y_pred)\n",
    "        rec = recall(y_true, y_pred)\n",
    "        return -(1+1)*(presci * rec)/(1*presci + rec)\n",
    "    return fscore_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "fscore_weights = (1,1)\n",
    "\n",
    "criterion = weighted_fscore_loss(*fscore_weights)\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "lrscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "measures = {'dice_coeff':dice_coef, \n",
    "            'iou':iou, \n",
    "            'fp': falsepos, \n",
    "            'fn': falseneg, \n",
    "            'precision': precision, \n",
    "            'recall': recall, \n",
    "            'fscore': fscore }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train\n",
    "\n",
    "from visualization import Visualization\n",
    "\n",
    "vis = Visualization('Mean loss')\n",
    "\n",
    "measurement_log = []\n",
    "for epoch in range(10):\n",
    "    measurements = train.fit(net, train_loader, val_loader, criterion, optimizer, lrscheduler, measures, epoch, vis)\n",
    "    measurement_log.append(measurements)\n",
    "    print(\"Epoch: %d: \" % epoch, end='')\n",
    "    for k,v in measurements.items():\n",
    "        print(\" {}:{:.5f}\".format(k,v), end=',')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "timestamp = time.strftime('%m%d%H%M')\n",
    "os.mkdir('./output_%s'%timestamp)\n",
    "\n",
    "# write out weights\n",
    "torch.save(net.state_dict(), './output_%s/ultrasound.pth' % timestamp)\n",
    "\n",
    "# write out log\n",
    "with open('./output_%s/info.txt' % timestamp, 'w') as f:\n",
    "    f.write('%s\\n' % time.strftime('%m-%d %H:%M'))\n",
    "    f.write('optimizer: %s\\n' % type(optimizer).__name__)\n",
    "    f.write('scheduler: %s\\n' % type(lrscheduler).__name__)\n",
    "    f.write('learning_rate: %.6f\\n' % learning_rate)\n",
    "    f.write('fscore_weights: preci:%d, recall:%d\\n' % fscore_weights)\n",
    "    f.write('\\n')\n",
    "    \n",
    "with open('./output_%s/measurements.txt' % timestamp, 'w') as f:\n",
    "    wr = csv.writer(f)\n",
    "    wr.writerow([\"Epoch\"] + list(measurements.keys()))\n",
    "    for epoch,measurement in enumerate(measurement_log):\n",
    "        wr.writerow([epoch] + list(measurement.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_HT = 416\n",
    "IMAGE_WD = 576\n",
    "\n",
    "dataiter = iter(val_loader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.cuda()\n",
    "output = net(images)\n",
    "\n",
    "\n",
    "for idx in range(10):\n",
    "    x, y, label = images[idx], output[idx], labels[idx]\n",
    "    \n",
    "    y = y.reshape(IMAGE_HT, IMAGE_WD).cpu().detach().numpy()\n",
    "    label = label.reshape(IMAGE_HT, IMAGE_WD).cpu().detach().numpy()\n",
    "\n",
    "    # convert image to HSV for annotations\n",
    "    img = x.cpu().detach().numpy()\n",
    "    img = (img + 1) * 127\n",
    "    img = img.astype(np.uint8)\n",
    "    img = np.dstack((img[0,:,:], img[1,:,:], img[2,:,:]))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    # apply prediction and label markings\n",
    "    h = img[:,:,0]\n",
    "    s = img[:,:,1]\n",
    "    h[y > .75] += 50 # GREEN\n",
    "    s[y > .75] = 250\n",
    "    h[label > .75] += 100 # BLUE\n",
    "    s[label > .75] = 250\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_HSV2RGB)\n",
    "    \n",
    "    cv2.imwrite('./output_%s/%d.jpg'%(timestamp,idx), img)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch-1.0)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
